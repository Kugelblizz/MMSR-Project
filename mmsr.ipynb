{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS AND SETTINGS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import product\n",
    "import csv\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make display(...) show all rows of a dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFS\n",
    "\n",
    "# extract string movieId from movieclipId (without leading zeros)\n",
    "def str_movie_id(movieclip_id):\n",
    "    return str(movie_id(movieclip_id))\n",
    "\n",
    "# extract int movieId from movieclipId\n",
    "def movie_id(movieclip_id):\n",
    "    return int(movieclip_id.split('_')[0])\n",
    "\n",
    "# calculate precision and tag coverage for the results of a single query\n",
    "def rate(qresults, ks):\n",
    "    qmovie_id = qresults.movieId.head(1) \n",
    "    rating = pd.DataFrame(index=[qmovie_id])\n",
    "    for k in ks:\n",
    "        rmovie_ids = [movie_id(y) for y in qresults.movieclipId.head(k)]\n",
    "        # rate relevance    \n",
    "        qgenres = genres.loc[qmovie_id]\n",
    "        rgenres = genres.loc[rmovie_ids]\n",
    "        rjscore = rgenres.apply(lambda row: jaccard_score(qgenres.values[0], row), axis=1)\n",
    "        prec = len(rjscore[rjscore > 0.5]) / len(rjscore)\n",
    "        rating['P@' + str(k)] = prec\n",
    "        # rate diversity\n",
    "        qtags = tags.loc[qmovie_id].iloc[0]\n",
    "        qtags = qtags[qtags > 0].index\n",
    "        rtags = tag_occs.loc[rmovie_ids].agg('sum')\n",
    "        rtags = rtags[rtags > 0]\n",
    "        urtags = rtags.index\n",
    "        rtags = np.repeat(rtags.index, rtags.values)\n",
    "        abs_tag_cov = len(urtags)\n",
    "        rel_tag_cov = (len(urtags) / len(qtags)) if len(qtags) > 0 else np.nan\n",
    "        rating['AbsTagCov@' + str(k)] = abs_tag_cov\n",
    "        rating['RelTagCov@' + str(k)] = rel_tag_cov\n",
    "        entropy = entropy_label_distribution(rtags)\n",
    "        rating['Entropy@' + str(k)] = entropy\n",
    "    return rating\n",
    "\n",
    "# Compute entropy of label distribution\n",
    "def entropy_label_distribution(labels):\n",
    "    n_labels = len(labels)\n",
    "    \n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    value, counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / np.float32(n_labels)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute entropy\n",
    "    ent = 0.0\n",
    "\n",
    "    for p in probs:\n",
    "        ent -= p * np.log(p)\n",
    "\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a2dec674ce4548b649d83561dcfec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='rating each query result of results.csv...', max=637.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78835f73b4f494da1670a2cbd45f56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='rating each query result of random_results.csv...', max=6…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@30</th>\n",
       "      <th>P@50</th>\n",
       "      <th>AbsTagCov@5</th>\n",
       "      <th>AbsTagCov@10</th>\n",
       "      <th>AbsTagCov@30</th>\n",
       "      <th>AbsTagCov@50</th>\n",
       "      <th>RelTagCov@5</th>\n",
       "      <th>RelTagCov@10</th>\n",
       "      <th>RelTagCov@30</th>\n",
       "      <th>RelTagCov@50</th>\n",
       "      <th>Entropy@5</th>\n",
       "      <th>Entropy@10</th>\n",
       "      <th>Entropy@30</th>\n",
       "      <th>Entropy@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Our algorithm (AVGd)</th>\n",
       "      <td>0.661224</td>\n",
       "      <td>0.404710</td>\n",
       "      <td>0.219623</td>\n",
       "      <td>0.174505</td>\n",
       "      <td>85.175824</td>\n",
       "      <td>207.362637</td>\n",
       "      <td>578.830455</td>\n",
       "      <td>852.825746</td>\n",
       "      <td>5.121694</td>\n",
       "      <td>16.235538</td>\n",
       "      <td>49.858747</td>\n",
       "      <td>77.051710</td>\n",
       "      <td>3.987829</td>\n",
       "      <td>5.066133</td>\n",
       "      <td>6.083332</td>\n",
       "      <td>6.415662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random baseline (AVGd)</th>\n",
       "      <td>0.062794</td>\n",
       "      <td>0.060283</td>\n",
       "      <td>0.058974</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>152.043956</td>\n",
       "      <td>280.452119</td>\n",
       "      <td>683.445840</td>\n",
       "      <td>984.938776</td>\n",
       "      <td>14.686209</td>\n",
       "      <td>27.723307</td>\n",
       "      <td>66.758688</td>\n",
       "      <td>95.826846</td>\n",
       "      <td>4.910344</td>\n",
       "      <td>5.539273</td>\n",
       "      <td>6.347228</td>\n",
       "      <td>6.636099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             P@5      P@10      P@30      P@50  AbsTagCov@5  \\\n",
       "Our algorithm (AVGd)    0.661224  0.404710  0.219623  0.174505    85.175824   \n",
       "Random baseline (AVGd)  0.062794  0.060283  0.058974  0.059121   152.043956   \n",
       "\n",
       "                        AbsTagCov@10  AbsTagCov@30  AbsTagCov@50  RelTagCov@5  \\\n",
       "Our algorithm (AVGd)      207.362637    578.830455    852.825746     5.121694   \n",
       "Random baseline (AVGd)    280.452119    683.445840    984.938776    14.686209   \n",
       "\n",
       "                        RelTagCov@10  RelTagCov@30  RelTagCov@50  Entropy@5  \\\n",
       "Our algorithm (AVGd)       16.235538     49.858747     77.051710   3.987829   \n",
       "Random baseline (AVGd)     27.723307     66.758688     95.826846   4.910344   \n",
       "\n",
       "                        Entropy@10  Entropy@30  Entropy@50  \n",
       "Our algorithm (AVGd)      5.066133    6.083332    6.415662  \n",
       "Random baseline (AVGd)    5.539273    6.347228    6.636099  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESULTS FILE EVALUATION \n",
    "\n",
    "def eval(filename):\n",
    "    results = pd.read_csv(filename)  \n",
    "    results_per_query = results.groupby('movieId')\n",
    "    tqdm_notebook.pandas(desc='rating each query result of %s...' % filename)\n",
    "    ks = [5, 10, 30, 50]\n",
    "    ratings = results_per_query.progress_apply(lambda x: rate(x, ks))\n",
    "    ratings.index = ratings.index.get_level_values(0)\n",
    "    agg_ratings = ratings.agg('mean')\n",
    "    agg_ratings = agg_ratings[[label + str(k) for label, k in product(['P@', 'AbsTagCov@', 'RelTagCov@', 'Entropy@'], ks)]]\n",
    "    return agg_ratings\n",
    "    \n",
    "our_algorithm = eval('results.csv')\n",
    "random_baseline = eval('random_results.csv')\n",
    "df = pd.DataFrame([our_algorithm, random_baseline], index=['Our algorithm (AVGd)', 'Random baseline (AVGd)'])\n",
    "df.to_csv('evaluation.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PARSING AND PREPARATION\n",
    "\n",
    "# parse data\n",
    "# TODO use testset when finally generating results file to hand in...\n",
    "movies = pd.read_csv('MMSR_dataset_2019/devset_movies.csv', index_col='movieId')\n",
    "clips = pd.read_csv('MMSR_dataset_2019/devset_ids.csv', index_col='movieId')\n",
    "tags = pd.read_csv('MMSR_dataset_2019/features/Metadata/devset_TagFeatures.csv', index_col='movieId')\n",
    "genres = pd.read_csv('MMSR_dataset_2019/features/Metadata/devset_GenreFeatures.csv', index_col='movieId')\n",
    "# TODO use all BLFs instead of just SPECTRAL (I don't have enough RAM for that...)\n",
    "#blfs = pd.read_csv('MMSR_dataset_2019/features/Audio/Block level features/Component6/BLF_SPECTRAL_fullId.csv', header=None, index_col=0)\n",
    "blfs = pd.read_csv('MMSR_dataset_2019/features/Audio/Block level features/All/BLF_all_fullId.csv', header=None, index_col=0)\n",
    "alexnet = pd.read_csv('MMSR_dataset_2019/features/Visual/Deep AlexNetFc7/Avg/AlexNetFeatures - AVG - fc7.csv', header=None, index_col=0)\n",
    "\n",
    "# fix missing or superfluous movies or clips in features\n",
    "tags = movies.join(tags).drop('title', axis=1).fillna(0)\n",
    "genres = movies.join(genres).drop('title', axis=1).fillna(0)\n",
    "blfs = clips.join(blfs, on='movieclipId').set_index('movieclipId').fillna(0)\n",
    "alexnet = clips.join(alexnet, on='movieclipId').set_index('movieclipId').fillna(0)\n",
    "\n",
    "# normalize and reduce dimensionality...\n",
    "scaler = MinMaxScaler()\n",
    "pca = PCA(n_components=0.9)\n",
    "red_tags = pd.DataFrame(pca.fit_transform(scaler.fit_transform(tags)), index=tags.index)\n",
    "blfs = pd.DataFrame(pca.fit_transform(scaler.fit_transform(blfs)), index=blfs.index)\n",
    "alexnet = pd.DataFrame(pca.fit_transform(scaler.fit_transform(alexnet)), index=alexnet.index)\n",
    "\n",
    "# precompute tag occurrences for calculating tag coverage\n",
    "tag_occs = tags > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf11d5ffcd61412aa6560234992e4e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=637.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION USING BLFS, ALEXNET AND TAGS\n",
    "max_clips_per_movie = 5\n",
    "results = pd.DataFrame(columns=['movieId', 'movieclipId', 'sim', 'rank']).set_index(['movieId', 'movieclipId'])\n",
    "\n",
    "# compute average feature vector of audio and visual features for (all clips of) a movie\n",
    "qblfs = blfs.groupby(lambda x: movie_id(x)).mean()\n",
    "qalexnet = alexnet.groupby(lambda x: movie_id(x)).mean()\n",
    "# compute movie tag distances\n",
    "movie_similarity_meta = pd.DataFrame(cosine_distances(tags), index=movies.index, columns=movies.index.values)\n",
    "\n",
    "for qmovie_id in tqdm_notebook(movies.index):\n",
    "    # create multiple clip rankings...\n",
    "    # rank clips by audio distance using manhattan distance from average BLF vector of query\n",
    "    ranked_clips_audio = pd.DataFrame(manhattan_distances(blfs.values, qblfs.loc[qmovie_id].values.reshape(1, -1)), \n",
    "                                        index=clips['movieclipId'], \n",
    "                                       columns=['dist']).sort_values('dist')\n",
    "    # rank clips by visual distance using manhattan distance from average AlexNet vector of query\n",
    "    ranked_clips_visual = pd.DataFrame(manhattan_distances(alexnet.values, qalexnet.loc[qmovie_id].values.reshape(1, -1)),\n",
    "                                        index=clips['movieclipId'], \n",
    "                                        columns=['dist']).sort_values('dist')\n",
    "    # rank clips by metadata distance (take one random clip per movie)\n",
    "    ranked_clips_meta = movie_similarity_meta[qmovie_id].reset_index().rename({qmovie_id:'dist'}, axis=1)\n",
    "    ranked_clips_meta['movieclipId'] = ranked_clips_meta['movieId'].apply(lambda mid: clips.loc[mid].sample(1).iloc[0]['movieclipId'] if len(clips.loc[mid]) > 1 else clips.loc[mid].sample(1)['movieclipId'])\n",
    "    ranked_clips_meta = ranked_clips_meta.set_index('movieclipId')[['dist']].sort_values('dist')\n",
    "\n",
    "    # retrieve most similar clips (alternate between audio, visual and metadata features)\n",
    "    # never take more than 5 clips from the same movie! (to keep it interesting)\n",
    "    qresult = pd.DataFrame(columns=['movieId', 'movieclipId', 'sim', 'rank'])\n",
    "\n",
    "    while len(qresult) < 100:\n",
    "        if len(qresult) % 3 == 0:\n",
    "            source = ranked_clips_visual\n",
    "        elif len(qresult) % 3 == 1:\n",
    "            source = ranked_clips_audio\n",
    "        else:\n",
    "            source = ranked_clips_meta\n",
    "        for i in range(0, len(source)):\n",
    "            rcandidate = source.iloc[i]\n",
    "            is_new_clip = not rcandidate.name in qresult['movieclipId'].values\n",
    "            rmovie_id = movie_id(rcandidate.name)\n",
    "            is_movie_allowed = len(qresult.loc[qresult['movieId'] == rmovie_id]) < max_clips_per_movie\n",
    "            if is_new_clip & is_movie_allowed:\n",
    "                if len(qresult) % 3 == 0:\n",
    "                    ranked_clips_audio = source.iloc[i:]\n",
    "                elif len(qresult) % 3 == 1:\n",
    "                    ranked_clips_visual = source.iloc[i:]\n",
    "                else:\n",
    "                    ranked_clips_meta = source.iloc[i:]\n",
    "                qresult.loc[len(qresult)] = [qmovie_id, rcandidate.name, rcandidate.dist, len(qresult)]\n",
    "                break\n",
    "\n",
    "    # transform distances into similarity measure (i.e. invert it)\n",
    "    qresult['sim'] = qresult['sim'].map(lambda x: 1 / (1 + float(x)))\n",
    "    results = pd.concat([results, qresult], sort=False)\n",
    "\n",
    "results.to_csv('results.csv', columns=['movieId', 'movieclipId', 'sim', 'rank'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1dcdcf4f9e544ac81d54e0172217be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=637.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION PICKING CLIPS RANDOMLY (AS BASELINE)\n",
    "\n",
    "qmovies = np.repeat(movies.index, 100)\n",
    "rclips = np.array([clips['movieclipId'].sample(100) for i in tqdm_notebook(range(len(movies.index)))]).flatten()\n",
    "random_results = pd.DataFrame([qmovies, rclips]).transpose()\n",
    "random_results.columns = ['movieId', 'movieclipId']\n",
    "random_results['sim'] = np.repeat(0.0, len(random_results))\n",
    "random_results['rank'] = np.array([np.arange(100) for i in range(len(movies.index))]).flatten()\n",
    "random_results.to_csv('random_results.csv', columns=['movieId', 'movieclipId', 'sim', 'rank'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BLFS', 0.1171875, 0.1875, 0.1732283464566929, 0.09448818897637795, 0.16535433070866143]\n",
      "['ALEXNET', 0.1015625, 0.171875, 0.15748031496062992, 0.11811023622047244, 0.12598425196850394]\n",
      "['TAGS', 0.0859375, 0.0625, 0.031496062992125984, 0.03937007874015748, 0.10236220472440945]\n",
      "['COMBINED MEAN', 0.09375, 0.1484375, 0.15748031496062992, 0.13385826771653545, 0.13385826771653545]\n"
     ]
    }
   ],
   "source": [
    "# TODO!\n",
    "# find a way to predict movie genres with decent accuracy...\n",
    "# then integrate the predicted genres somehow in the algorithm that generates the results file... \n",
    "# (e.g. use them to calculate the jaccard index of currently retrieved movies in order to ensure a certain precision?)\n",
    "# idea: maybe use weaker dimensionality reduction (PCA parameter currently at 0.9) and maybe prediction results will improve...?\n",
    "\n",
    "y = genres.values\n",
    "\n",
    "# predict movie genre from audio features\n",
    "X = qblfs.values\n",
    "blfs_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "blfs_score = cross_val_score(blfs_clf, X, y, cv=5)\n",
    "blfs_score = blfs_score.tolist()\n",
    "blfs_score.insert(0, \"BLFS\")\n",
    "print(blfs_score)\n",
    "\n",
    "# predict movie genre from video features\n",
    "X = qalexnet.values\n",
    "alexnet_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "alexnet_score = cross_val_score(alexnet_clf, X, y, cv=5)\n",
    "alexnet_score = alexnet_score.tolist()\n",
    "alexnet_score.insert(0, \"ALEXNET\")\n",
    "print(alexnet_score)\n",
    "\n",
    "# predict movie genre from metadata\n",
    "X = red_tags.values\n",
    "tags_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "tags_score = cross_val_score(tags_clf, X, y, cv=5)\n",
    "tags_score = tags_score.tolist()\n",
    "tags_score.insert(0, \"TAGS\")\n",
    "print(tags_score)\n",
    "\n",
    "# predict movie genre from averaged audio/visual/metadata features\n",
    "X = pd.concat([qblfs, qalexnet, red_tags]).groupby(lambda x: x).mean()\n",
    "all_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "all_score = cross_val_score(all_clf, X, y, cv=5)\n",
    "all_score = all_score.tolist()\n",
    "all_score.insert(0, \"COMBINED MEAN\")\n",
    "print(all_score)\n",
    "\n",
    "with open('svm_scores.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Type\", \"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "    writer.writerow(blfs_score)\n",
    "    writer.writerow(alexnet_score)\n",
    "    writer.writerow(tags_score)\n",
    "    writer.writerow(all_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
