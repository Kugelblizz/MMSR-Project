{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS AND SETTINGS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make display(...) show all rows of a dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFS\n",
    "\n",
    "# extract string movieId from movieclipId (without leading zeros)\n",
    "def str_movie_id(movieclip_id):\n",
    "    return str(movie_id(movieclip_id))\n",
    "\n",
    "# extract int movieId from movieclipId\n",
    "def movie_id(movieclip_id):\n",
    "    return int(movieclip_id.split('_')[0])\n",
    "\n",
    "# calculate precision and tag coverage for the results of a single query\n",
    "def rate(qresults, ks):\n",
    "    qmovie_id = qresults.movieId.head(1)    \n",
    "    rating = pd.DataFrame(index=[qmovie_id])\n",
    "    for k in ks:\n",
    "        rmovie_ids = [movie_id(y) for y in qresults.movieclipId.head(k)]\n",
    "        # rate relevance    \n",
    "        qgenres = genres.loc[qmovie_id]\n",
    "        rgenres = genres.loc[rmovie_ids]\n",
    "        rjscore = rgenres.apply(lambda row: jaccard_score(qgenres.values[0], row), axis=1)\n",
    "        prec = len(rjscore[rjscore > 0.5]) / len(rjscore)\n",
    "        rating['P@' + str(k)]= prec\n",
    "        # rate diversity\n",
    "        qtags = tags.loc[qmovie_id].iloc[0]\n",
    "        qtags = qtags[qtags > 0].index\n",
    "        rtags = tag_occs.loc[rmovie_ids].agg('sum')\n",
    "        rtags = rtags[rtags > 0]\n",
    "        urtags = rtags.index\n",
    "        rtags = np.repeat(rtags.index, rtags.values)\n",
    "        abs_tag_cov = len(urtags)\n",
    "        if (len(qtags)!= 0): #sometimes len(qtags) = 0 and the function fails\n",
    "            #TODO review if (I don't if it's correct)\n",
    "            rel_tag_cov = len(urtags) / len(qtags) \n",
    "        else:\n",
    "            rel_tag_cov = 0\n",
    "        rating['AbsTagCov@' + str(k)] = abs_tag_cov\n",
    "        rating['RelTagCov@' + str(k)] = rel_tag_cov\n",
    "        entropy = entropy_label_distribution(rtags) # TODO rtags should not be unique!\n",
    "        rating['Entropy@' + str(k)] = entropy\n",
    "    return rating\n",
    "\n",
    "# Compute entropy of label distribution\n",
    "def entropy_label_distribution(labels):\n",
    "    n_labels = len(labels)\n",
    "    \n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    value, counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / np.float32(n_labels)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute entropy\n",
    "    ent = 0.0\n",
    "\n",
    "    for p in probs:\n",
    "        ent -= p * np.log(p)\n",
    "\n",
    "    return ent\n",
    "\n",
    "#computes jaccard similarity between genders\n",
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))\n",
    "\n",
    "# returns the genre of the element in i position on the dataframe r1\n",
    "def get_genre_of_filmsclip (i, r1):\n",
    "    candidate = r1.iloc[i] # get the element\n",
    "    aux = r1[r1['dist']==candidate.dist].index.values.astype(str) #obtain an array with index of the element\n",
    "    movieIdaux = aux[0] #get the first item of the array\n",
    "    movieIdaux = movieIdaux[0:9] #get the part we are interested in (the movie id)\n",
    "    int(movieIdaux) # convert form str to integer\n",
    "    genre_movie_aux = genres.loc[int(movieIdaux)] #get gender\n",
    "    return genre_movie_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ece51484ad43d59babf8bf1c3dc60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='rating each query result...', max=637.0, style=ProgressStâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@5</th>\n",
       "      <th>AbsTagCov@5</th>\n",
       "      <th>RelTagCov@5</th>\n",
       "      <th>Entropy@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>AbsTagCov@10</th>\n",
       "      <th>RelTagCov@10</th>\n",
       "      <th>Entropy@10</th>\n",
       "      <th>P@30</th>\n",
       "      <th>AbsTagCov@30</th>\n",
       "      <th>RelTagCov@30</th>\n",
       "      <th>Entropy@30</th>\n",
       "      <th>P@50</th>\n",
       "      <th>AbsTagCov@50</th>\n",
       "      <th>RelTagCov@50</th>\n",
       "      <th>Entropy@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.454003</td>\n",
       "      <td>113.514914</td>\n",
       "      <td>8.284021</td>\n",
       "      <td>4.472338</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>205.651491</td>\n",
       "      <td>16.362307</td>\n",
       "      <td>5.077554</td>\n",
       "      <td>0.244532</td>\n",
       "      <td>530.133438</td>\n",
       "      <td>46.280857</td>\n",
       "      <td>5.995674</td>\n",
       "      <td>0.195542</td>\n",
       "      <td>776.098901</td>\n",
       "      <td>70.022916</td>\n",
       "      <td>6.327790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>4.611382</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>7.357143</td>\n",
       "      <td>5.160461</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>20.545455</td>\n",
       "      <td>6.023773</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>29.826087</td>\n",
       "      <td>6.353841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.697653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.086608</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.678893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>5.814003</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>6.067454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>905.000000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>6.554224</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>912.000000</td>\n",
       "      <td>6.720955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P@5  AbsTagCov@5  RelTagCov@5  Entropy@5      P@10  AbsTagCov@10  \\\n",
       "mean    0.454003   113.514914     8.284021   4.472338  0.389325    205.651491   \n",
       "median  0.400000   106.000000     3.769231   4.611382  0.400000    201.000000   \n",
       "min     0.000000     1.000000     0.000000   0.000000  0.000000     20.000000   \n",
       "max     1.000000   355.000000   152.000000   5.814003  0.900000    490.000000   \n",
       "\n",
       "        RelTagCov@10  Entropy@10      P@30  AbsTagCov@30  RelTagCov@30  \\\n",
       "mean       16.362307    5.077554  0.244532    530.133438     46.280857   \n",
       "median      7.357143    5.160461  0.233333    524.000000     20.545455   \n",
       "min         0.000000    2.697653  0.000000    197.000000      0.000000   \n",
       "max       320.000000    6.067454  0.666667    905.000000    667.000000   \n",
       "\n",
       "        Entropy@30      P@50  AbsTagCov@50  RelTagCov@50  Entropy@50  \n",
       "mean      5.995674  0.195542    776.098901     70.022916    6.327790  \n",
       "median    6.023773  0.180000    776.000000     29.826087    6.353841  \n",
       "min       5.086608  0.020000    398.000000      0.000000    5.678893  \n",
       "max       6.554224  0.480000   1205.000000    912.000000    6.720955  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RESULTS FILE EVALUATION \n",
    "\n",
    "results = pd.read_csv('results.csv')    \n",
    "results_per_query = results.groupby('movieId')\n",
    "tqdm_notebook.pandas(desc='rating each query result...')\n",
    "# TODO this is super slow...\n",
    "ratings = results_per_query.progress_apply(lambda x: rate(x, [5, 10, 30, 50]))\n",
    "ratings.index = ratings.index.get_level_values(0)\n",
    "agg_ratings = ratings.agg(['mean', 'median', 'min', 'max'])\n",
    "display(agg_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_pca.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    }
   ],
   "source": [
    "# DATA PARSING AND PREPARATION\n",
    "\n",
    "# parse data\n",
    "# We need to use the testset, not the devset of data\n",
    "movies = pd.read_csv('MMSR_dataset_2019/testset_movies.csv', index_col='movieId')\n",
    "clips = pd.read_csv('MMSR_dataset_2019/testset_ids.csv', index_col='movieId')\n",
    "tags = pd.read_csv('MMSR_dataset_2019/features/Metadata/devset_TagFeatures.csv', index_col='movieId')\n",
    "genres = pd.read_csv('MMSR_dataset_2019/features/Metadata/devset_GenreFeatures.csv', index_col='movieId')\n",
    "# TODO use all BLFs instead of just SPECTRAL (I don't have enough RAM for that...) -> DONE, I don't have any \n",
    "# problem with the RAM\n",
    "\n",
    "#blfs = pd.read_csv('MMSR_dataset_2019/features/Audio/Block level features/Component6/BLF_SPECTRAL_fullId.csv', header=None, index_col=0)\n",
    "blfs = pd.read_csv('MMSR_dataset_2019/features/Audio/Block level features/All/BLF_all_fullId.csv', header=None, index_col=0)\n",
    "\n",
    "alexnet = pd.read_csv('MMSR_dataset_2019/features/Visual/Deep AlexNetFc7/Avg/AlexNetFeatures - AVG - fc7.csv', header=None, index_col=0)\n",
    "\n",
    "# fix missing or superfluous movies or clips in features\n",
    "tags = movies.join(tags).drop('title', axis=1).fillna(0)\n",
    "genres = movies.join(genres).drop('title', axis=1).fillna(0)\n",
    "blfs = clips.join(blfs, on='movieclipId').set_index('movieclipId').fillna(0)\n",
    "alexnet = clips.join(alexnet, on='movieclipId').set_index('movieclipId').fillna(0)\n",
    "\n",
    "# normalize and reduce dimensionality...\n",
    "scaler = MinMaxScaler()\n",
    "pca = PCA(n_components=0.9)\n",
    "red_tags = pd.DataFrame(pca.fit_transform(scaler.fit_transform(tags)), index=tags.index)\n",
    "blfs = pd.DataFrame(pca.fit_transform(scaler.fit_transform(blfs)), index=blfs.index)\n",
    "alexnet = pd.DataFrame(pca.fit_transform(scaler.fit_transform(alexnet)), index=alexnet.index)\n",
    "\n",
    "# precompute tag occurrences for calculating tag coverage\n",
    "tag_occs = tags > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc9f5527bbd4e4ca96cf0f96ca8a62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DECENT? SOLUTION USING BLFS AND ALEXNET \n",
    "\n",
    "results = pd.DataFrame(columns=['movieId', 'movieclipId', 'sim', 'rank'])\n",
    "results.set_index(['movieId', 'movieclipId'])\n",
    "\n",
    "# 1) compute single feature vector for metadata, audio and visual features for (all clips of) a movie\n",
    "#qtags = tags.groupby(lambda x: movie_id(x)).mean()\n",
    "qblfs = blfs.groupby(lambda x: movie_id(x)).mean()\n",
    "qalexnet = alexnet.groupby(lambda x: movie_id(x)).mean()\n",
    "\n",
    "for movieId in tqdm_notebook(movies.index):\n",
    "    # 2) rank clips by computing distance to aggregated feature vectors of this movie\n",
    "    ranked_clips_audio = pd.DataFrame(euclidean_distances(blfs.values, qblfs.loc[movieId].values.reshape(1, -1)), \n",
    "                                        index=clips.movieclipId, \n",
    "                                       columns=['dist']).sort_values('dist')\n",
    "    ranked_clips_visual = pd.DataFrame(euclidean_distances(alexnet.values, qalexnet.loc[movieId].values.reshape(1, -1)),\n",
    "                                        index=clips.movieclipId, \n",
    "                                        columns=['dist']).sort_values('dist')\n",
    "    \n",
    "    genre_movie_query= genres.loc[movieId] # genre of the query movie\n",
    "    \n",
    "    # 3) take most similar clips (alternate between audio and visual features) but at most 3 of the same movie\n",
    "    qresult = pd.DataFrame(columns=['movieclipId', 'sim']).set_index('movieclipId')\n",
    "    movie_counter = pd.DataFrame(np.zeros(len(movies)), index=movies.index, columns=['counter'])\n",
    "    while len(qresult) < 100:\n",
    "        source = ranked_clips_audio if len(qresult) % 2 == 0 else ranked_clips_visual\n",
    "        for i in range(0, len(source)):\n",
    "            \n",
    "            rcandidate = source.iloc[i]\n",
    "          \n",
    "        #JACCARD COEFFICIENT (doesn't work because the genres of testset are missing)\n",
    "            l1=get_genre_of_filmsclip(i, source)\n",
    "            if  jaccard_similarity(l1,genre_movie_query) >= 0.5:\n",
    "                is_jaccard = True\n",
    "            else:\n",
    "                is_jaccard = False\n",
    "            \n",
    "            is_new_clip = not rcandidate.name in qresult.index\n",
    "            is_movie_allowed = movie_counter.loc[movie_id(rcandidate.name)].counter < 3\n",
    "            if is_new_clip & is_movie_allowed & is_jaccard:\n",
    "                # didn't work because it was written movie_allowed instead of is_movie_allowed\n",
    "                if len(qresult) % 2 == 0:\n",
    "                    ranked_clips_audio = source.iloc[i:] # deletes the element we have just worked with\n",
    "                else:\n",
    "                    ranked_clips_visual = source.iloc[i:] #deletes the element we have just worked with\n",
    "                qresult.loc[rcandidate.name] = rcandidate.dist\n",
    "                break\n",
    "    \n",
    "    # fixup ranks and movieId\n",
    "    \n",
    "    \n",
    "   \n",
    "    qresult['rank'] = np.arange(100)\n",
    "    qresult['movieId'] = np.full(100, movieId)\n",
    "    # transform euclidean distance into similarity measure \n",
    "    # instead of using the cosine, we use 1/(1+x) to have measures between 0 and 1\n",
    "    qresult['sim'] = qresult['sim'].map(lambda x: 1 / (1 + x))\n",
    "    results = pd.concat([results, qresult], sort=False)\n",
    "    \n",
    "results.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "results.columns = ['movieclipId', 'movieId','','sim', 'rank'] \n",
    "# added one more column to results because it needs to have five columns, not four (don't exactly know why we\n",
    "# need it)\n",
    "results = results.astype({'movieId':int})\n",
    "results = results.astype({'movieclipId':str})\n",
    "\n",
    "\n",
    "results.to_csv('results2.csv', columns=['movieId', 'movieclipId', 'sim', 'rank'], index=False)\n",
    "# result with 15900 lines (+ header) that we are asked for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd20f71c79d4316b46cd495dfd36dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BAD SOLUTION USING ONLY METADATA\n",
    "\n",
    "# compute cosine similarities between tag tf_idf vectors\n",
    "tags_cos_sim = pd.DataFrame(cosine_similarity(tags.values),\n",
    "                            columns=tags.index.values, \n",
    "                            index=tags.index)\n",
    "\n",
    "# generate results file\n",
    "results = pd.DataFrame(columns=['movieId', 'movieclipId', 'sim', 'rank'])\n",
    "\n",
    "for movieId in tqdm_notebook(movies.index):\n",
    "    sim = tags_cos_sim[[movieId]]\n",
    "    sim = sim.reset_index()\n",
    "    sim = sim.rename(columns={movieId : 'sim', 'movieId': 'otherMovieId'})\n",
    "    sim = sim.join(clips, on='otherMovieId', how='outer')\n",
    "    sim = sim.reset_index(drop=True)\n",
    "    sim = sim.drop('otherMovieId', axis=1)\n",
    "    sim = sim.sort_values('sim', ascending=False)\n",
    "    sim = sim.head(100)\n",
    "    sim['rank'] = np.arange(100)\n",
    "    sim['movieId'] = np.full(100, movieId)\n",
    "    results = pd.concat([results, sim], ignore_index=True)\n",
    "results.to_csv('results.csv', columns=['movieId', 'movieclipId', 'sim', 'rank'], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-09d69f767809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
