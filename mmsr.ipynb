{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS AND SETTINGS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from itertools import product\n",
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make display(...) show all rows of a dataframe\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFS\n",
    "\n",
    "# extract string movieId from movieclipId (without leading zeros)\n",
    "def str_movie_id(movieclip_id):\n",
    "    return str(movie_id(movieclip_id))\n",
    "\n",
    "# extract int movieId from movieclipId\n",
    "def movie_id(movieclip_id):\n",
    "    return int(movieclip_id.split('_')[0])\n",
    "\n",
    "# calculate precision and tag coverage for the results of a single query\n",
    "def rate(qresults, ks):\n",
    "    qmovie_id = qresults.movieId.head(1) \n",
    "    rating = pd.DataFrame(index=[qmovie_id])\n",
    "    for k in ks:\n",
    "        rmovie_ids = [movie_id(y) for y in qresults.movieclipId.head(k)]\n",
    "        # rate relevance    \n",
    "        qgenres = genres.loc[qmovie_id]\n",
    "        rgenres = genres.loc[rmovie_ids]\n",
    "        rjscore = rgenres.apply(lambda row: jaccard_score(qgenres.values[0], row), axis=1)\n",
    "        prec = len(rjscore[rjscore > 0.5]) / len(rjscore)\n",
    "        rating['P@' + str(k)] = prec\n",
    "        # rate diversity\n",
    "        qtags = tags.loc[qmovie_id].iloc[0]\n",
    "        qtags = qtags[qtags > 0].index\n",
    "        rtags = tag_occs.loc[rmovie_ids].agg('sum')\n",
    "        rtags = rtags[rtags > 0]\n",
    "        urtags = rtags.index\n",
    "        rtags = np.repeat(rtags.index, rtags.values)\n",
    "        abs_tag_cov = len(urtags)\n",
    "        rel_tag_cov = (len(urtags) / len(qtags)) if len(qtags) > 0 else np.nan\n",
    "        rating['AbsTagCov@' + str(k)] = abs_tag_cov\n",
    "        rating['RelTagCov@' + str(k)] = rel_tag_cov\n",
    "        entropy = entropy_label_distribution(rtags)\n",
    "        rating['Entropy@' + str(k)] = entropy\n",
    "    return rating\n",
    "\n",
    "# Compute entropy of label distribution\n",
    "def entropy_label_distribution(labels):\n",
    "    n_labels = len(labels)\n",
    "    \n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "\n",
    "    value, counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / np.float32(n_labels)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute entropy\n",
    "    ent = 0.0\n",
    "\n",
    "    for p in probs:\n",
    "        ent -= p * np.log(p)\n",
    "\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dff65c59dd4485ba810f2809f6524a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='rating each query result of results.csv...', max=637, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7237f0706c1d4dbaa7bce7967dcd676f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='rating each query result of random_results.csv...', max=637, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@30</th>\n",
       "      <th>P@50</th>\n",
       "      <th>AbsTagCov@5</th>\n",
       "      <th>AbsTagCov@10</th>\n",
       "      <th>AbsTagCov@30</th>\n",
       "      <th>AbsTagCov@50</th>\n",
       "      <th>RelTagCov@5</th>\n",
       "      <th>RelTagCov@10</th>\n",
       "      <th>RelTagCov@30</th>\n",
       "      <th>RelTagCov@50</th>\n",
       "      <th>Entropy@5</th>\n",
       "      <th>Entropy@10</th>\n",
       "      <th>Entropy@30</th>\n",
       "      <th>Entropy@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Our algorithm (AVGd)</td>\n",
       "      <td>0.454003</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>0.244532</td>\n",
       "      <td>0.195542</td>\n",
       "      <td>113.514914</td>\n",
       "      <td>205.651491</td>\n",
       "      <td>530.133438</td>\n",
       "      <td>776.098901</td>\n",
       "      <td>8.456605</td>\n",
       "      <td>16.703188</td>\n",
       "      <td>47.245041</td>\n",
       "      <td>71.481727</td>\n",
       "      <td>4.472338</td>\n",
       "      <td>5.077554</td>\n",
       "      <td>5.995674</td>\n",
       "      <td>6.327790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random baseline (AVGd)</td>\n",
       "      <td>0.054317</td>\n",
       "      <td>0.059184</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.059749</td>\n",
       "      <td>146.872841</td>\n",
       "      <td>272.860283</td>\n",
       "      <td>675.530612</td>\n",
       "      <td>985.715856</td>\n",
       "      <td>14.768404</td>\n",
       "      <td>26.835700</td>\n",
       "      <td>66.811813</td>\n",
       "      <td>96.496674</td>\n",
       "      <td>4.881937</td>\n",
       "      <td>5.513404</td>\n",
       "      <td>6.336756</td>\n",
       "      <td>6.636864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             P@5      P@10      P@30      P@50  AbsTagCov@5  \\\n",
       "Our algorithm (AVGd)    0.454003  0.389325  0.244532  0.195542   113.514914   \n",
       "Random baseline (AVGd)  0.054317  0.059184  0.060440  0.059749   146.872841   \n",
       "\n",
       "                        AbsTagCov@10  AbsTagCov@30  AbsTagCov@50  RelTagCov@5  \\\n",
       "Our algorithm (AVGd)      205.651491    530.133438    776.098901     8.456605   \n",
       "Random baseline (AVGd)    272.860283    675.530612    985.715856    14.768404   \n",
       "\n",
       "                        RelTagCov@10  RelTagCov@30  RelTagCov@50  Entropy@5  \\\n",
       "Our algorithm (AVGd)       16.703188     47.245041     71.481727   4.472338   \n",
       "Random baseline (AVGd)     26.835700     66.811813     96.496674   4.881937   \n",
       "\n",
       "                        Entropy@10  Entropy@30  Entropy@50  \n",
       "Our algorithm (AVGd)      5.077554    5.995674    6.327790  \n",
       "Random baseline (AVGd)    5.513404    6.336756    6.636864  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESULTS FILE EVALUATION \n",
    "\n",
    "def eval(filename):\n",
    "    results = pd.read_csv(filename)  \n",
    "    results_per_query = results.groupby('movieId')\n",
    "    tqdm_notebook.pandas(desc='rating each query result of %s...' % filename)\n",
    "    ks = [5, 10, 30, 50]\n",
    "    ratings = results_per_query.progress_apply(lambda x: rate(x, ks))\n",
    "    ratings.index = ratings.index.get_level_values(0)\n",
    "    agg_ratings = ratings.agg('mean')\n",
    "    agg_ratings = agg_ratings[[label + str(k) for label, k in product(['P@', 'AbsTagCov@', 'RelTagCov@', 'Entropy@'], ks)]]\n",
    "    return agg_ratings\n",
    "    \n",
    "our_algorithm = eval('results.csv')\n",
    "random_baseline = eval('random_results.csv')\n",
    "pd.DataFrame([our_algorithm, random_baseline], index=['Our algorithm (AVGd)', 'Random baseline (AVGd)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PARSING AND PREPARATION\n",
    "\n",
    "# parse data\n",
    "# TODO use testset when finally generating results file to hand in...\n",
    "movies = pd.read_csv('MMSR_dataset_2019/devset_movies.csv', index_col='movieId')\n",
    "clips = pd.read_csv('MMSR_dataset_2019/devset_ids.csv', index_col='movieId')\n",
    "tags = pd.read_csv('MMSR_dataset_2019/features/Metadata/devset_TagFeatures.csv', index_col='movieId')\n",
    "genres = pd.read_csv('MMSR_dataset_2019/features/Metadata/devset_GenreFeatures.csv', index_col='movieId')\n",
    "# TODO use all BLFs instead of just SPECTRAL (I don't have enough RAM for that...)\n",
    "blfs = pd.read_csv('MMSR_dataset_2019/features/Audio/Block level features/Component6/BLF_SPECTRAL_fullId.csv', header=None, index_col=0)\n",
    "alexnet = pd.read_csv('MMSR_dataset_2019/features/Visual/Deep AlexNetFc7/Avg/AlexNetFeatures - AVG - fc7.csv', header=None, index_col=0)\n",
    "\n",
    "# fix missing or superfluous movies or clips in features\n",
    "tags = movies.join(tags).drop('title', axis=1).fillna(0)\n",
    "genres = movies.join(genres).drop('title', axis=1).fillna(0)\n",
    "blfs = clips.join(blfs, on='movieclipId').set_index('movieclipId').fillna(0)\n",
    "alexnet = clips.join(alexnet, on='movieclipId').set_index('movieclipId').fillna(0)\n",
    "\n",
    "# normalize and reduce dimensionality...\n",
    "scaler = MinMaxScaler()\n",
    "pca = PCA(n_components=0.9)\n",
    "red_tags = pd.DataFrame(pca.fit_transform(scaler.fit_transform(tags)), index=tags.index)\n",
    "blfs = pd.DataFrame(pca.fit_transform(scaler.fit_transform(blfs)), index=blfs.index)\n",
    "alexnet = pd.DataFrame(pca.fit_transform(scaler.fit_transform(alexnet)), index=alexnet.index)\n",
    "\n",
    "# precompute tag occurrences for calculating tag coverage\n",
    "tag_occs = tags > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION USING BLFS AND ALEXNET \n",
    "\n",
    "results = pd.DataFrame(columns=['movieId', 'movieclipId', 'sim', 'rank']).set_index(['movieId', 'movieclipId'])\n",
    "\n",
    "# 1) compute average feature vector of audio and visual features for (all clips of) a movie\n",
    "qblfs = blfs.groupby(lambda x: movie_id(x)).mean()\n",
    "qalexnet = alexnet.groupby(lambda x: movie_id(x)).mean()\n",
    "\n",
    "for movieId in tqdm_notebook(movies.index):\n",
    "    # 2) rank clips by computing distance to aggregated feature vectors of this movie\n",
    "    ranked_clips_audio = pd.DataFrame(euclidean_distances(blfs.values, qblfs.loc[movieId].values.reshape(1, -1)), \n",
    "                                        index=clips.movieclipId, \n",
    "                                       columns=['dist']).sort_values('dist')\n",
    "    ranked_clips_visual = pd.DataFrame(euclidean_distances(alexnet.values, qalexnet.loc[movieId].values.reshape(1, -1)),\n",
    "                                        index=clips.movieclipId, \n",
    "                                        columns=['dist']).sort_values('dist')\n",
    "    \n",
    "    # 3) take most similar clips (alternate between audio and visual features) but at most 3 of the same movie\n",
    "    qresult = pd.DataFrame(columns=['movieclipId', 'sim']).set_index('movieclipId')\n",
    "    movie_counter = pd.DataFrame(np.zeros(len(movies)), index=movies.index, columns=['counter'])\n",
    "    while len(qresult) < 100:\n",
    "        source = ranked_clips_audio if len(qresult) % 2 == 0 else ranked_clips_visual\n",
    "        for i in range(0, len(source)):\n",
    "            rcandidate = source.iloc[i]\n",
    "            is_new_clip = not rcandidate.name in qresult.index\n",
    "            is_movie_allowed = movie_counter.loc[movie_id(rcandidate.name)].counter < 3\n",
    "            if is_new_clip & is_movie_allowed:\n",
    "                if len(qresult) % 2 == 0:\n",
    "                    ranked_clips_audio = source.iloc[i:]\n",
    "                else:\n",
    "                    ranked_clips_visual = source.iloc[i:]\n",
    "                qresult.loc[rcandidate.name] = rcandidate.dist\n",
    "                break\n",
    "    \n",
    "    # fixup ranks and movieId\n",
    "    qresult['rank'] = np.arange(100)\n",
    "    qresult['movieId'] = np.full(100, movieId)\n",
    "    # transform euclidean distance into similarity measure (i.e. invert it)\n",
    "    qresult['sim'] = qresult['sim'].map(lambda x: 1 / (1 + x))\n",
    "    results = pd.concat([results, qresult], sort=False)\n",
    "    \n",
    "results.reset_index(inplace=True)\n",
    "results.columns = ['movieclipId', 'sim', 'rank', 'movieId']\n",
    "results = results.astype({'movieId':int})\n",
    "results.to_csv('results.csv', columns=['movieId', 'movieclipId', 'sim', 'rank'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf27c6235764411bf4335687ee68087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=637), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION PICKING CLIPS RANDOMLY (AS BASELINE)\n",
    "\n",
    "qmovies = np.repeat(movies.index, 100)\n",
    "rclips = np.array([clips['movieclipId'].sample(100) for i in tqdm_notebook(range(len(movies.index)))]).flatten()\n",
    "random_results = pd.DataFrame([qmovies, rclips]).transpose()\n",
    "random_results.columns = ['movieId', 'movieclipId']\n",
    "random_results['sim'] = np.repeat(0.0, len(random_results))\n",
    "random_results['rank'] = np.array([np.arange(100) for i in range(len(movies.index))]).flatten()\n",
    "random_results.to_csv('random_results.csv', columns=['movieId', 'movieclipId', 'sim', 'rank'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO!\n",
    "# find a way to predict movie genres with decent accuracy...\n",
    "# then integrate the predicted genres somehow in the algorithm that generates the results file... \n",
    "# (e.g. use them to calculate the jaccard index of currently retrieved movies in order to ensure a certain precision?)\n",
    "# idea: maybe use weaker dimensionality reduction (PCA parameter currently at 0.9) and maybe prediction results will improve...?\n",
    "y = genres.values\n",
    "\n",
    "# predict movie genre from audio features\n",
    "X = qblfs.values\n",
    "blfs_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "print(cross_val_score(blfs_clf, X, y, cv=5))\n",
    "\n",
    "# predict movie genre from video features\n",
    "X = qalexnet.values\n",
    "alexnet_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "print(cross_val_score(alexnet_clf, X, y, cv=5))\n",
    "\n",
    "# predict movie genre from metadata\n",
    "X = red_tags.values\n",
    "tags_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "print(cross_val_score(tags_clf, X, y, cv=5))\n",
    "\n",
    "# predict movie genre from averaged audio/visual/metadata features\n",
    "X = pd.concat([qblfs, qalexnet, red_tags]).groupby(lambda x: x).mean()\n",
    "all_clf = OneVsRestClassifier(SVC(gamma='scale'))\n",
    "print(cross_val_score(all_clf, X, y, cv=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
